{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dd5bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('setup working!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55faf281",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro, kstest, chi2_contingency\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"setup done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Fraud_Detection_Dataset.csv')\n",
    "df_clean = df.copy()\n",
    "df_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e17da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for information and description\n",
    "df_clean.info()\n",
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe and shape\n",
    "df_clean.describe()\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485769b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for unique values\n",
    "df_clean.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ea24d",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop fraudulent rows that have na to ensures that the dataset only contains rows with a valid label for model training\n",
    "df_clean.dropna(subset=['Fraudulent'], inplace = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305752a9",
   "metadata": {},
   "source": [
    "drop transaction id as it is just an identifier and it is not useful when it comes to determining whether a transaction is fruadulent or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396963e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop transaction id\n",
    "df_clean.drop('Transaction_ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate numerical values and catagorical values\n",
    "num_cols =  ['Transaction_Amount', 'Time_of_Transaction',\n",
    "            'Previous_Fraudulent_Transactions', 'Account_Age',\n",
    "            'Number_of_Transactions_Last_24H']\n",
    "\n",
    "\n",
    "cat_cols =  ['Transaction_Type', 'Device_Used', 'Location', 'Payment_Method']\n",
    "print(f\"Numerical Columns: {num_cols}\")\n",
    "print(f\"Categorical Columns: {cat_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe520ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check missing values\n",
    "missing_values = df_clean.isnull().sum().sort_values(ascending =False)\n",
    "percentage_missing_values = ((missing_values / len(df_clean)) * 100).sort_values(ascending =False)\n",
    "pd.concat([missing_values, percentage_missing_values], axis=1, keys=['Total', 'Percentage']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check skewness to determine which method to use to imputate the missing values\n",
    "df_clean[num_cols].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74720956",
   "metadata": {},
   "source": [
    "since we know that data is missing completely at random, therefore we can imputate mode, mean, median for frauduelent and transaction amount respectively and for categorial data i can use mode imputation as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c81e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median\n",
    "df_clean['Transaction_Amount'].fillna(df_clean['Transaction_Amount'].median(), inplace=True)\n",
    "#median\n",
    "df_clean['Time_of_Transaction'].fillna(df_clean['Time_of_Transaction'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode\n",
    "for cat_col in cat_cols:\n",
    "    df_clean[cat_col].fillna(df_clean[cat_col].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7086f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values again\n",
    "missing_values = df_clean.isnull().sum().sort_values(ascending =False)\n",
    "percentage_missing_values = ((missing_values / len(df_clean )) * 100).sort_values(ascending =False)\n",
    "pd.concat([missing_values, percentage_missing_values], axis=1, keys=['Total', 'Percentage']).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f2f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicates\n",
    "duplicates = df_clean.duplicated().sum()\n",
    "print('Total Duplicates:', df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d95b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "df_clean.drop_duplicates(inplace=True)\n",
    "print(\"Remaining duplicates:\", df_clean.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa5e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check shape and fraudulent rate\n",
    "print(df_clean.shape)\n",
    "print(f'Fraudulent Rate: {df_clean[\"Fraudulent\"].mean():.2%}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change dtypes\n",
    "df_clean['Transaction_Type'] = df_clean['Transaction_Type'].astype('category')\n",
    "df_clean['Payment_Method'] = df_clean['Payment_Method'].astype('category')\n",
    "df_clean['Device_Used'] = df_clean['Device_Used'].astype('category')\n",
    "df_clean['Location'] = df_clean['Location'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16061fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the changes\n",
    "df_clean.head()\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08014bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_clean.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c22af",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe69955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transections per user\n",
    "transactions_per_user = df_clean['User_ID'].value_counts()\n",
    "print(\"Number of transactions per user:\")\n",
    "display(transactions_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25421757",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 5 users with the most transactions:\")\n",
    "display(transactions_per_user.head(5))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950df843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize class imbalace\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Fraudulent', data=df_clean, palette='Set2')\n",
    "plt.title('Class Imbalance Visualization')\n",
    "for i, count in enumerate(df_clean['Fraudulent'].value_counts()):\n",
    "    plt.text(i, count + 1, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Fraudulent')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90684048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation_matrix\n",
    "num_df = df_clean[num_cols + ['Fraudulent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dfed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlation matrix\n",
    "correlation_matrix = num_df.corr()\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cbadf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relationship between fraud and transaction amount\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Fraudulent', y='Transaction_Amount', data=df_clean)\n",
    "plt.title('Relationship between Fraudulent and Transaction Amount')\n",
    "plt.xlabel('Fraudulent')\n",
    "plt.ylabel('Transaction Amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4075c00d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c86d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relationship between account age and fraudulent\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.violinplot(x='Fraudulent', y='Account_Age', data=df_clean, palette='Set1')\n",
    "\n",
    "plt.title('Relationship between Fraudulent and Account Age')\n",
    "plt.xlabel('Fraudulent')\n",
    "plt.ylabel('Account Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de15a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relationship between time of transaction and fraudulent\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Time_of_Transaction', hue='Fraudulent', data=df_clean, palette='Set1')\n",
    "plt.title('Relationship between Time of Transaction and Fraudulent')\n",
    "plt.xlabel('Time of Transaction')\n",
    "plt.ylabel('Count')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ecc12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi2 graph for catagorical catagorical features\n",
    "for col in cat_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    fraud_rate = df_clean.groupby(col)['Fraudulent'].mean().sort_values(ascending=False)\n",
    "    sns.barplot(x=fraud_rate.index, y=fraud_rate.values, palette='coolwarm')\n",
    "    plt.title(f'Fraud Rate by {col}')\n",
    "    plt.ylabel('Proportion of Fraudulent Transactions')\n",
    "    plt.xlabel(col)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba30bef5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ad59e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save new csv\n",
    "df_clean.to_csv('df_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check new csv\n",
    "df_cleaned = pd.read_csv('df_clean.csv')\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8138f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check info and shape\n",
    "df_cleaned.info()\n",
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ace24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of your dataframe\n",
    "df_encoded = df_cleaned.copy()\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df_encoded.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b14f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical columns IN PLACE (replacing original)\n",
    "for col in categorical_cols:\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "    print(f\"Encoded column: {col}\")\n",
    "\n",
    "# confirm all columns are numeric\n",
    "print(\"\\n Data types after encoding:\")\n",
    "print(df_encoded.dtypes)\n",
    "\n",
    "# verify number of columns\n",
    "print(f\"\\n Final number of columns: {df_encoded.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b966de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display first few rows of the encoded dataframe\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca74fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save into csv\n",
    "df_encoded.to_csv('df_encoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e264fcb5",
   "metadata": {},
   "source": [
    "Assumptions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5eeef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "df_encoded = pd.read_csv('df_encoded.csv')\n",
    "df_encoded = df_encoded.copy()\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97517a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assume\n",
    "X = df_encoded.drop('Fraudulent', axis=1)\n",
    "y = df_encoded['Fraudulent']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e63e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Balance Check\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ASSUMPTION 1: CLASS BALANCE\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "fraud_counts = df_encoded['Fraudulent'].value_counts()\n",
    "fraud_ratio = fraud_counts[1] / fraud_counts[0]\n",
    "\n",
    "print(f\"\\nClass Distribution:\")\n",
    "print(f\"  Non-Fraud: {fraud_counts[0]:,} ({fraud_counts[0]/len(df_encoded)*100:.2f}%)\")\n",
    "print(f\"  Fraud:     {fraud_counts[1]:,} ({fraud_counts[1]/len(df_encoded)*100:.2f}%)\")\n",
    "print(f\"  Imbalance Ratio: 1:{1/fraud_ratio:.1f}\")\n",
    "\n",
    "if fraud_ratio < 0.1:\n",
    "    print(\"\\n WARNING: Severe class imbalance detected!\")\n",
    "    print(\"   Recommendation:\")\n",
    "    print(\"   - Use class_weight='balanced' in models\")\n",
    "    print(\"   - Consider SMOTE or undersampling\")\n",
    "    print(\"   - Use stratified cross-validation\")\n",
    "    print(\"   - Focus on Precision-Recall metrics over Accuracy\")\n",
    "else:\n",
    "    print(\"\\nClasses are reasonably balanced\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4561a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#M#ASSUMPTION 3: Feature Correlations & Multicollinearity\n",
    "# ============================================================================\n",
    "# Compute VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# Sort results for clarity\n",
    "vif_data = vif_data.sort_values('VIF', ascending=False)\n",
    "print(\"\\n VIF Results:\")\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db3ea5",
   "metadata": {},
   "source": [
    "Features are not strongly correlated.\n",
    "\n",
    "No features need to be removed for linear models.\n",
    "\n",
    "Tree-based models like Random Forest can safely use all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a331c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASSUMPTION 3: OUTLIERS DETECTION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ASSUMPTION 3: OUTLIERS DETECTION\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "outlier_summary = []\n",
    "for col in df_encoded:\n",
    "    if col in df_encoded.columns:\n",
    "        Q1 = df_encoded[col].quantile(0.25)\n",
    "        Q3 = df_encoded[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers = df_encoded[(df_encoded[col] < lower_bound) | (df_encoded[col] > upper_bound)]\n",
    "        outlier_pct = len(outliers) / len(df_encoded) * 100\n",
    "\n",
    "        outlier_summary.append({\n",
    "            'Feature': col,\n",
    "            'Outliers': len(outliers),\n",
    "            'Percentage': outlier_pct,\n",
    "            'Lower_Bound': lower_bound,\n",
    "            'Upper_Bound': upper_bound\n",
    "        })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "print(\"\\nOutlier Summary (IQR method):\")\n",
    "print(outlier_df.to_string(index=False))\n",
    "\n",
    "severe_outliers = outlier_df[outlier_df['Percentage'] > 5]\n",
    "if len(severe_outliers) > 0:\n",
    "    print(\"\\n  WARNING: Significant outliers detected!\")\n",
    "    print(\"   Impact on models:\")\n",
    "    print(\"   - Logistic Regression: Moderate (can affect coefficients)\")\n",
    "    print(\"   - KNN: High (distance-based, sensitive to outliers)\")\n",
    "    print(\"   - Tree-based: Low (splits handle outliers naturally)\")\n",
    "    print(\"\\n   Recommendations:\")\n",
    "    print(\"   - Consider robust scaling for KNN and Logistic Regression\")\n",
    "    print(\"   - Investigate if outliers are fraud cases (could be legitimate signal)\")\n",
    "else:\n",
    "    print(\"\\n No severe outlier issues detected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d43a381",
   "metadata": {},
   "source": [
    "Transaction Amount has a few outliers (~1%).\n",
    "\n",
    "Could be very small or very large transactions.\n",
    "\n",
    "Might be worth visualizing using boxplots.\n",
    "\n",
    "Fraudulent class shows up as an “outlier” in counts because fraud is rare (~5%).\n",
    "\n",
    "This is not a data error; it’s just reflecting class imbalance.\n",
    "\n",
    "All other features don’t show severe outliers, so your data is generally clean and ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ASSUMPTION 4: FEATURE DISTRIBUTIONS\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ASSUMPTION 4: FEATURE DISTRIBUTIONS (Normality)\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\nShapiro-Wilk Test for Normality (sample of 5000):\")\n",
    "print(\"(p-value > 0.05 suggests normal distribution)\")\n",
    "\n",
    "normality_results = []\n",
    "for col in num_cols:\n",
    "    if col in df_encoded.columns:\n",
    "        sample = df_encoded[col].sample(min(5000, len(df_encoded)), random_state=42)\n",
    "        statistic, p_value = shapiro(sample)\n",
    "        is_normal = \"Yes\" if p_value > 0.05 else \"No\"\n",
    "        normality_results.append({\n",
    "            'Feature': col,\n",
    "            'Statistic': statistic,\n",
    "            'P-Value': p_value,\n",
    "            'Normal': is_normal\n",
    "        })\n",
    "\n",
    "normality_df = pd.DataFrame(normality_results)\n",
    "print(normality_df.to_string(index=False))\n",
    "\n",
    "non_normal = normality_df[normality_df['Normal'] == 'No']\n",
    "if len(non_normal) > 0:\n",
    "    print(\"\\n Most features are not normally distributed\")\n",
    "    print(\"   Impact on models:\")\n",
    "    print(\"   - Logistic Regression: Low (assumes linearity, not normality of features)\")\n",
    "    print(\"   - KNN: Low (distance-based, doesn't require normality)\")\n",
    "    print(\"   - Tree-based: None (no normality assumption)\")\n",
    "    print(\"\\n   Note: Non-normality of features is common and often acceptable\")\n",
    "else:\n",
    "    print(\"\\n Features are approximately normally distributed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ef2264",
   "metadata": {},
   "source": [
    "Observation: Most features are not normally distributed, which is very common in financial and transactional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ed82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ASSUMPTION 5: LINEAR RELATIONSHIP (for Logistic Regression)\n",
    "\n",
    "print(\"ASSUMPTION 5: LINEAR RELATIONSHIP WITH LOG-ODDS (Logistic Regression)\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\nChecking linearity between continuous features and log-odds...\")\n",
    "print(\"(Using Box-Tidwell transformation test)\")\n",
    "\n",
    "# For each continuous feature, check linearity with logit\n",
    "linear_check = []\n",
    "for col in num_cols:\n",
    "    if col in df_encoded.columns and col != 'Fraudulent':\n",
    "        # Add small constant to avoid log(0)\n",
    "        feature_log = np.log(df_encoded[col] + 1)\n",
    "        correlation = df_encoded[col].corr(df_encoded['Fraudulent'])\n",
    "\n",
    "        linear_check.append({\n",
    "            'Feature': col,\n",
    "            'Correlation_with_Target': correlation,\n",
    "            'Likely_Linear': 'Yes' if abs(correlation) > 0.1 else 'Weak'\n",
    "        })\n",
    "\n",
    "linear_df = pd.DataFrame(linear_check)\n",
    "print(linear_df.to_string(index=False))\n",
    "\n",
    "weak_linear = linear_df[linear_df['Likely_Linear'] == 'Weak']\n",
    "if len(weak_linear) > 0:\n",
    "    print(f\"\\n {len(weak_linear)} features show weak linear relationship with target\")\n",
    "    print(\"   This may affect Logistic Regression performance\")\n",
    "    print(\"   Consider polynomial features or non-linear models\")\n",
    "else:\n",
    "    print(\"\\n Features show reasonable linear relationships\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4899b7ad",
   "metadata": {},
   "source": [
    "All continuous features show very weak correlation with the log-odds of fraud.\n",
    "\n",
    "Weak linearity suggests logistic regression may not fully capture the relationship.\n",
    "\n",
    "This is common in fraud detection, as fraudulent patterns are often non-linear and sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b5c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSUMPTION 6: INDEPENDENCE OF OBSERVATIONS\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ASSUMPTION 6: INDEPENDENCE OF OBSERVATIONS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\nChecking for duplicate transactions...\")\n",
    "duplicates = df_encoded.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicates}\")\n",
    "\n",
    "print(\"\\n Checking User_ID transaction patterns...\")\n",
    "user_txn_counts = df_encoded['User_ID'].value_counts()\n",
    "print(f\"Unique users: {len(user_txn_counts)}\")\n",
    "print(f\"Avg transactions per user: {user_txn_counts.mean():.2f}\")\n",
    "print(f\"Max transactions per user: {user_txn_counts.max()}\")\n",
    "\n",
    "repeat_users = user_txn_counts[user_txn_counts > 10]\n",
    "if len(repeat_users) > 0:\n",
    "    print(f\"\\n  {len(repeat_users)} users have >10 transactions\")\n",
    "    print(\"   This violates independence assumption\")\n",
    "    print(\"   Impact on models:\")\n",
    "    print(\"   - Standard errors may be underestimated\")\n",
    "    print(\"   - Consider user-level aggregation or random effects models\")\n",
    "    print(\"   - Use stratified sampling by User_ID for train/test split\")\n",
    "else:\n",
    "    print(\"\\n Observations appear independent\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13404608",
   "metadata": {},
   "source": [
    "On average, each user has ~12 transactions.\n",
    "\n",
    "Some users have as many as 26 transactions.\n",
    "\n",
    "2826 users have more than 10 transactions → this is important because:\n",
    "\n",
    "Logistic regression and other models assume observations are independent.\n",
    "\n",
    "When a user has multiple transactions, their transactions may not be independent:\n",
    "\n",
    "Fraud patterns could repeat per user.\n",
    "\n",
    "The model might “see” the same user multiple times, inflating feature importance.\n",
    "\n",
    "Non-independence can cause overfitting, especially if one user dominates the fraud class.\n",
    "\n",
    "Tree-based models are less sensitive to this, but it’s still something to be aware of.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSUMPTION 7: NO DATA LEAKAGE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ASSUMPTION 7: DATA LEAKAGE CHECK\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\n Checking for potential data leakage...\")\n",
    "\n",
    "leakage_features = ['Previous_Fraudulent_Transactions']\n",
    "print(f\"\\n  CRITICAL: '{leakage_features[0]}' may indicate data leakage!\")\n",
    "print(\"   This feature should be calculated from PAST transactions only\")\n",
    "print(\"   If it includes the current transaction, it's leakage\")\n",
    "\n",
    "# Check if previous fraud is perfectly correlated with target\n",
    "leakage_corr = df_encoded['Previous_Fraudulent_Transactions'].corr(df_encoded['Fraudulent'])\n",
    "print(f\"\\n   Correlation with target: {leakage_corr:.4f}\")\n",
    "\n",
    "if leakage_corr > 0.3:\n",
    "    print(\"     WARNING: Strong correlation suggests possible leakage\")\n",
    "    print(\"   Verify this feature is computed from historical data only\")\n",
    "else:\n",
    "    print(\"    Correlation seems reasonable\")\n",
    "\n",
    "# Check temporal ordering if Time_of_Transaction exists\n",
    "print(\"\\nTemporal ordering check...\")\n",
    "if 'Time_of_Transaction' in df_encoded.columns:\n",
    "    print(\"    Time feature available for temporal validation\")\n",
    "    print(\"   Ensure train/test split respects temporal order for production\")\n",
    "else:\n",
    "    print(\"     No explicit time ordering - ensure no future data in features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835110aa",
   "metadata": {},
   "source": [
    "We're checking if any feature gives the model access to information it shouldn’t have when making predictions. The feature Previous_Fraudulent_Transactions might leak data if it includes the current transaction, because that would give the model a peek at the answer.\n",
    "\n",
    "We also look at the time feature to make sure the train/test split respects chronological order, so the model only learns from past transactions. Overall, the correlation with the target is very low (0.0008), so it seems safe, but we need to confirm the feature only uses past information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c76dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample Size Adequency\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ASSUMPTION 8: SAMPLE SIZE ADEQUACY\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "n_samples = len(df_encoded)\n",
    "n_features = len(df_encoded.drop('Fraudulent', axis=1).columns)\n",
    "n_fraud = df_encoded['Fraudulent'].sum()\n",
    "n_non_fraud = len(df_encoded) - n_fraud\n",
    "\n",
    "print(f\"\\nSample size: {n_samples:,}\")\n",
    "print(f\"Number of features: {n_features}\")\n",
    "print(f\"Fraud cases: {n_fraud:,}\")\n",
    "print(f\"Non-fraud cases: {n_non_fraud:,}\")\n",
    "\n",
    "# Rule of thumb: 10-20 events per predictor for logistic regression\n",
    "min_events_needed = n_features * 10\n",
    "print(f\"\\nMinimum fraud cases needed (10 per feature): {min_events_needed}\")\n",
    "\n",
    "if n_fraud >= min_events_needed:\n",
    "    print(f\" Adequate fraud samples: {n_fraud} >= {min_events_needed}\")\n",
    "else:\n",
    "    print(f\"  WARNING: Insufficient fraud samples: {n_fraud} < {min_events_needed}\")\n",
    "    print(\"   This may affect model reliability, especially Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b7ca2",
   "metadata": {},
   "source": [
    "Your sample size is adequate for model training. Both the overall dataset and minority class have sufficient data. The main issue remains imbalance, not insufficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57cf04b",
   "metadata": {},
   "source": [
    "Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc12f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.read_csv('df_encoded.csv')\n",
    "df_encoded = df_encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9939b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial models \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# Use your clean encoded df\n",
    "X_baseline = df_encoded.drop(['Fraudulent', 'User_ID'], axis=1)\n",
    "y_baseline = df_encoded['Fraudulent']\n",
    "#baseline models\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_baseline, y_baseline, test_size=0.2, random_state=42, stratify=y_baseline\n",
    ")\n",
    "def train_raw_models(X_train, y_train, X_test, y_test):\n",
    "    models = {\n",
    "        \"Logistic_Regression\": LogisticRegression(max_iter=500),\n",
    "        \"Random_Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "        \"Gradient_Boosting\": GradientBoostingClassifier(n_estimators=200, random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"XGBoost\": XGBClassifier(n_estimators=300, max_depth=5, learning_rate=0.05,\n",
    "                                 subsample=0.8, colsample_bytree=0.8,\n",
    "                                 n_jobs=-1, eval_metric=\"logloss\", random_state=42),\n",
    "        \"LightGBM\": LGBMClassifier(n_estimators=300, learning_rate=0.05,\n",
    "                                   num_leaves=63, random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        print(f\"AUC={auc:.4f}\")\n",
    "        print(classification_report(y_test, y_pred, target_names=['Non-Fraud','Fraud']))\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "        results[name] = {\"auc\": auc}\n",
    "    return results\n",
    "\n",
    "# Example usage (before feature engineering)\n",
    "results = train_raw_models(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c1a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "\n",
    "def create_advanced_features(df_encoded):\n",
    "    \"\"\"Create powerful features for fraud detection models with refinements\"\"\"\n",
    "    print(\"Creating advanced features for model training...\")\n",
    "    df_advanced = df_encoded.copy()\n",
    "\n",
    "    # User behavior analytics\n",
    "    user_stats = df_advanced.groupby('User_ID').agg({\n",
    "        'Transaction_Amount': ['mean', 'std', 'min', 'max', 'count'],\n",
    "        'Time_of_Transaction': ['mean', 'std'],\n",
    "        'Fraudulent': ['sum', 'mean']\n",
    "    }).fillna(0)\n",
    "\n",
    "    user_stats.columns = [\n",
    "        'user_avg_amount', 'user_std_amount', 'user_min_amount', 'user_max_amount', 'user_total_txns',\n",
    "        'user_avg_time', 'user_std_time', 'user_fraud_count', 'user_fraud_rate_raw'\n",
    "    ]\n",
    "    df_advanced = df_advanced.merge(user_stats, on='User_ID', how='left')\n",
    "\n",
    "    # Fraud rate smoothing (Laplace)\n",
    "    df_advanced['user_fraud_rate'] = (\n",
    "        (df_advanced['user_fraud_count'] + 1) /\n",
    "        (df_advanced['user_total_txns'] + 2)\n",
    "    )\n",
    "\n",
    "    # Transaction patterns\n",
    "    df_advanced['amount_to_avg_ratio'] = df_advanced['Transaction_Amount'] / (df_advanced['user_avg_amount'] + 1)\n",
    "    df_advanced['amount_std_score'] = (df_advanced['Transaction_Amount'] - df_advanced['user_avg_amount']) / (df_advanced['user_std_amount'] + 1)\n",
    "\n",
    "    # Clip extreme values\n",
    "    df_advanced['amount_std_score'] = np.clip(df_advanced['amount_std_score'], -5, 5)\n",
    "\n",
    "    # Time-based features\n",
    "    df_advanced['hour_of_day'] = df_advanced['Time_of_Transaction'] % 24\n",
    "    df_advanced['is_night'] = ((df_advanced['hour_of_day'] >= 22) | (df_advanced['hour_of_day'] <= 6)).astype(int)\n",
    "    df_advanced['is_weekend'] = ((df_advanced['Time_of_Transaction'] // 24) % 7 >= 5).astype(int)\n",
    "    df_advanced['time_sin'] = np.sin(2 * np.pi * df_advanced['hour_of_day'] / 24)\n",
    "    df_advanced['time_cos'] = np.cos(2 * np.pi * df_advanced['hour_of_day'] / 24)\n",
    "\n",
    "    # Behavioral features\n",
    "    df_advanced['txn_frequency'] = df_advanced['user_total_txns'] / (df_advanced['Account_Age'] + 1)\n",
    "    df_advanced['recent_activity_ratio'] = df_advanced['Number_of_Transactions_Last_24H'] / (df_advanced['user_total_txns'] + 1)\n",
    "\n",
    "    # Composite risk feature (clipped)\n",
    "    df_advanced['composite_risk_1'] = (\n",
    "        df_advanced['Previous_Fraudulent_Transactions'] *\n",
    "        df_advanced['amount_std_score'] *\n",
    "        df_advanced['is_night']\n",
    "    )\n",
    "    df_advanced['composite_risk_1'] = np.clip(df_advanced['composite_risk_1'], -5, 5)\n",
    "\n",
    "    # Risk encoding for categorical variables\n",
    "    device_risk = {'Unknown Device': 3, 'Mobile': 2, 'Tablet': 1, 'Desktop': 0}\n",
    "    df_advanced['device_risk_score'] = df_advanced['Device_Used'].map(device_risk).fillna(0)\n",
    "\n",
    "    payment_risk = {'Invalid Method': 3, 'Credit Card': 2, 'Debit Card': 1, 'UPI': 0, 'Net Banking': 0}\n",
    "    df_advanced['payment_risk_score'] = df_advanced['Payment_Method'].map(payment_risk).fillna(0)\n",
    "\n",
    "    # Tiered fraud risk score (Low/Medium/High)\n",
    "    df_advanced['fraud_risk_tier'] = (\n",
    "        (df_advanced['user_fraud_rate'] > 0.2).astype(int) +\n",
    "        (df_advanced['recent_activity_ratio'] > 0.5).astype(int) +\n",
    "        (df_advanced['device_risk_score'] > 1).astype(int) +\n",
    "        (df_advanced['payment_risk_score'] > 1).astype(int)\n",
    "    )\n",
    "    # Map to categories\n",
    "    df_advanced['fraud_risk_tier'] = df_advanced['fraud_risk_tier'].map({0: 'Low', 1: 'Medium', 2: 'High', 3: 'High', 4: 'Critical'})\n",
    "\n",
    "    # Handle infinite values and NaN\n",
    "    df_advanced = df_advanced.replace([np.inf, -np.inf], 0)\n",
    "    df_advanced = df_advanced.fillna(0)\n",
    "\n",
    "    print(f\"Created {len([col for col in df_advanced.columns if col not in df_encoded.columns])} advanced features\")\n",
    "    return df_advanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f62258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advanced = create_advanced_features(df_encoded)  # make sure df_encoded exists\n",
    "\n",
    "# 2️ Save to CSV so you can reuse it later\n",
    "df_advanced.to_csv('df_advanced.csv', index=False)\n",
    "\n",
    "# 3(Optional) Reload later if needed\n",
    "df_advanced = pd.read_csv('df_advanced.csv')\n",
    "print(df_advanced.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb76784",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advanced.head()\n",
    "df_advanced.info()\n",
    "df_advanced.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa2386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "X = df_advanced.drop(['Fraudulent', 'User_ID'], axis=1)\n",
    "y = df_advanced['Fraudulent']\n",
    "\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Training samples: {X_train_1.shape}, Testing samples: {X_test_1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f195b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from evaluation import evaluate_model  # import your toolbox\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"df_advanced.csv\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "X = df.drop(columns=[\"Fraudulent\"]).select_dtypes(include=[\"number\"])\n",
    "y = df[\"Fraudulent\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"LogisticRegression_SMOTE\": LogisticRegression(max_iter=2000, class_weight=\"balanced\", solver=\"lbfgs\"),\n",
    "    \"LogisticRegression_NoSMOTE\": LogisticRegression(max_iter=2000, class_weight=\"balanced\", solver=\"lbfgs\"),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, max_depth=6, class_weight=\"balanced\", random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=200, max_depth=3, random_state=42),\n",
    "    \"KNN_SMOTE\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"KNN_NoSMOTE\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=200, max_depth=4, learning_rate=0.1,\n",
    "                             subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
    "                             use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluate all models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Toggle SMOTE: only skip for \"NoSMOTE\" versions\n",
    "    use_smote = False if \"NoSMOTE\" in name else True\n",
    "    results[name] = evaluate_model(model, X_train, y_train, X_test, y_test,\n",
    "                                   recall_target=0.8, use_smote=use_smote)\n",
    "\n",
    "# Convert results to DataFrame for leaderboard\n",
    "leaderboard = pd.DataFrame(results).T\n",
    "print(\"\\nLeaderboard:\\n\", leaderboard.sort_values(by=\"auc\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827b8c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "\n",
    "from evaluation import evaluate_model  # your toolbox\n",
    "\n",
    "# Define parameter grids\n",
    "param_grids = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"C\": [0.01, 0.1, 1, 10],\n",
    "        \"solver\": [\"lbfgs\", \"liblinear\"],\n",
    "        \"class_weight\": [\"balanced\"]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [4, 6, 8, None],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"class_weight\": [\"balanced\"]\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 4, 6]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 4, 6],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"colsample_bytree\": [0.8, 1.0]\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "        \"num_leaves\": [31, 50, 100],\n",
    "        \"max_depth\": [-1, 4, 6]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define base models\n",
    "base_models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=2000, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Run RandomizedSearchCV for each model\n",
    "tuned_results = {}\n",
    "for name, model in base_models.items():\n",
    "    print(f\"Tuning {name}...\")\n",
    "    rand_search = RandomizedSearchCV(\n",
    "        model,\n",
    "        param_distributions=param_grids[name],\n",
    "        n_iter=10,  # sample 10 random combos\n",
    "        cv=3,\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    rand_search.fit(X_train, y_train)\n",
    "    print(\"Best params:\", rand_search.best_params_)\n",
    "    \n",
    "    # Evaluate tuned model\n",
    "    best_model = rand_search.best_estimator_\n",
    "    tuned_results[name] = evaluate_model(best_model, X_train, y_train, X_test, y_test,\n",
    "                                         recall_target=0.8, use_smote=True)\n",
    "\n",
    "# Convert results to DataFrame for tuned leaderboard\n",
    "tuned_leaderboard = pd.DataFrame(tuned_results).T\n",
    "print(\"\\nTuned Leaderboard:\\n\", tuned_leaderboard.sort_values(by=\"auc\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32369bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After tuning GradientBoosting\n",
    "best_gb = rand_search.best_estimator_\n",
    "\n",
    "# After tuning LightGBM\n",
    "best_lgbm = rand_search.best_estimator_\n",
    "\n",
    "# After tuning XGBoost\n",
    "best_xgb = rand_search.best_estimator_\n",
    "\n",
    "# After tuning RandomForest\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# Logistic Regression baseline (keep the untuned one if tuned dropped performance)\n",
    "best_lr = LogisticRegression(max_iter=2000, solver=\"lbfgs\", class_weight=\"balanced\", random_state=42)\n",
    "best_lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd14ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "\n",
    "models = {\n",
    "    \"GradientBoosting\": best_gb,\n",
    "    \"LightGBM\": best_lgbm,\n",
    "    \"XGBoost\": best_xgb,\n",
    "    \"RandomForest\": best_rf,\n",
    "    \"LogisticRegression\": best_lr,\n",
    "    \"VotingClassifier\": ensemble\n",
    "}\n",
    "\n",
    "# ROC curves\n",
    "plt.figure(figsize=(10,7))\n",
    "for name, model in models.items():\n",
    "    y_scores = model.predict_proba(X_test)[:,1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "    auc = roc_auc_score(y_test, y_scores)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "plt.title(\"ROC Curves for All Models\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall curves\n",
    "plt.figure(figsize=(10,7))\n",
    "for name, model in models.items():\n",
    "    y_scores = model.predict_proba(X_test)[:,1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
    "    ap = average_precision_score(y_test, y_scores)\n",
    "    plt.plot(recall, precision, label=f\"{name} (AP={ap:.3f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curves for All Models (Tuned Models)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ddf248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for name, model in [(\"GradientBoosting\", best_gb),\n",
    "                    (\"LightGBM\", best_lgbm),\n",
    "                    (\"XGBoost\", best_xgb)]:\n",
    "    y_scores = model.predict_proba(X_test)[:,1]\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "    plt.plot(recall, precision, label=name)\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curves (Tuned Models)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84772049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "\n",
    "models = {\n",
    "    \"GradientBoosting\": best_gb,\n",
    "    \"LightGBM\": best_lgbm,\n",
    "    \"XGBoost\": best_xgb,\n",
    "    \"RandomForest\": best_rf,\n",
    "    \"LogisticRegression\": best_lr,\n",
    "    \"VotingClassifier\": ensemble\n",
    "}\n",
    "\n",
    "# ROC curves\n",
    "plt.figure(figsize=(10,7))\n",
    "for name, model in models.items():\n",
    "    y_scores = model.predict_proba(X_test)[:,1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "    auc = roc_auc_score(y_test, y_scores)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "plt.title(\"ROC Curves for All Models\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall curves\n",
    "plt.figure(figsize=(10,7))\n",
    "for name, model in models.items():\n",
    "    y_scores = model.predict_proba(X_test)[:,1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
    "    ap = average_precision_score(y_test, y_scores)\n",
    "    plt.plot(recall, precision, label=f\"{name} (AP={ap:.3f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curves for All Models\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a9c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def find_threshold_at_recall(model, X_test, y_test, target_recall=0.8):\n",
    "    \"\"\"Find threshold where recall is closest to target_recall and return precision, recall, threshold.\"\"\"\n",
    "    y_scores = model.predict_proba(X_test)[:,1]\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "    \n",
    "    # Find index where recall is closest to target\n",
    "    idx = np.argmin(np.abs(recall - target_recall))\n",
    "    return {\n",
    "        \"precision\": precision[idx],\n",
    "        \"recall\": recall[idx],\n",
    "        \"threshold\": thresholds[idx] if idx < len(thresholds) else 1.0\n",
    "    }\n",
    "\n",
    "# Collect results for each tuned model\n",
    "threshold_results = {}\n",
    "for name, model in [\n",
    "    (\"GradientBoosting\", best_gb),\n",
    "    (\"LightGBM\", best_lgbm),\n",
    "    (\"XGBoost\", best_xgb),\n",
    "    (\"RandomForest\", best_rf),\n",
    "    (\"LogisticRegression\", best_lr)  # baseline LR\n",
    "]:\n",
    "    threshold_results[name] = find_threshold_at_recall(model, X_test, y_test, target_recall=0.8)\n",
    "\n",
    "# Display results\n",
    "import pandas as pd\n",
    "threshold_df = pd.DataFrame(threshold_results).T\n",
    "print(\"\\nThresholds at Recall ≈ 0.8:\\n\", threshold_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"gb\", best_gb),\n",
    "        (\"lgbm\", best_lgbm),\n",
    "        (\"xgb\", best_xgb)\n",
    "    ],\n",
    "    voting=\"soft\"  # average predicted probabilities\n",
    ")\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate ensemble\n",
    "ensemble_results = evaluate_model(ensemble, X_train, y_train, X_test, y_test,\n",
    "                                  recall_target=0.8, use_smote=True)\n",
    "print(\"Ensemble results:\", ensemble_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a4ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# 1. Train champion model\n",
    "champion = LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=50,\n",
    "    max_depth=4,\n",
    "    random_state=42\n",
    ")\n",
    "champion.fit(X_train, y_train)\n",
    "\n",
    "# 2. Find threshold at recall ≈ 0.8\n",
    "y_scores = champion.predict_proba(X_test)[:,1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "idx = np.argmin(np.abs(recall - 0.8))\n",
    "best_threshold = thresholds[idx]\n",
    "\n",
    "print(f\"Champion: LightGBM | Threshold ≈ {best_threshold:.3f}\")\n",
    "print(f\"Precision: {precision[idx]:.3f}, Recall: {recall[idx]:.3f}\")\n",
    "\n",
    "# 3. Save model for deployment\n",
    "joblib.dump(champion, \"lightgbm_champion.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Target distribution\n",
    "sns.countplot(x=y)\n",
    "plt.title(\"Fraud vs Non-Fraud Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Percentage breakdown\n",
    "fraud_rate = (y.sum() / len(y)) * 100\n",
    "print(f\"Fraud cases: {y.sum()} ({fraud_rate:.2f}% of dataset)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Example with LightGBM champion\n",
    "y_scores = champion.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
    "auc = roc_auc_score(y_test, y_scores)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, label=f\"LightGBM (AUC = {auc:.3f})\")\n",
    "plt.plot([0,1],[0,1],'k--')  # diagonal line\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17425865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot feature importance\n",
    "importances = champion.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(features, importances)\n",
    "plt.title(\"LightGBM Feature Importance\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de127fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(champion)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
